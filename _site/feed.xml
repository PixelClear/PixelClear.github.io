<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Random Technical Rantings (Mostly about Graphics)</title>
    <description>This is my personal space to put my thoughts about graphics programming, optimizations, C &amp; C++ and different things I try out.
</description>
    <link>https://pixelclear.github.io/</link>
    <atom:link href="https://pixelclear.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 04 Nov 2017 20:59:42 +0100</pubDate>
    <lastBuildDate>Sat, 04 Nov 2017 20:59:42 +0100</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Understanding Image Filter Seperability!!</title>
        <description>&lt;p&gt;Normally in image processing we use 2D filters (which is 2D function) which is applied to image (which is also 2D function) to get some interesting effects like blur,edge detection,sharpening and so on.The result image is produces as sum of products of this two 2D functions.&lt;/p&gt;

&lt;p&gt;Now we can simplify this 2D filter by doing something know as filter separability. A two-dimensional filter &lt;strong&gt;“S”&lt;/strong&gt; is said to be separable if if it can be represented as convolution of two one-dimensional filters &lt;strong&gt;“V”&lt;/strong&gt; and &lt;strong&gt;“H”&lt;/strong&gt; such that &lt;strong&gt;S = V * H&lt;/strong&gt; .&lt;/p&gt;

&lt;p&gt;Suppose we have two-dimensional Gaussian distribution with a standard deviation of 0.85.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;h =
    0.0626    0.1250    0.0626
    0.1250    0.2497    0.1250
    0.0626    0.1250    0.0626
&lt;/div&gt;

&lt;p&gt;If you observe above matrix and perform some reduced row echelon operation on this matrix you will see this is matrix with rank 1. By rank one we mean that there is only one column with pivot element or in other words there is only one column and one row which are linearly independent.Matrices with rank 1 has special property that this matrices can be represented in &lt;strong&gt;ROW vector*COLUMN vector&lt;/strong&gt; form.For example,
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A =
    1   4   5
    2   8   10
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;

&lt;p&gt;A is Rank 1 Matrix.
So Lets break it up.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;row vector = 1 4 5
            
colomn vector= 1
               2﻿
&lt;/div&gt;

&lt;p&gt;Finally A can be written as A = row vector * column vector&lt;/p&gt;

&lt;p&gt;Similarly for h we have we need to find how to divide this in to simpler form.We can use &lt;strong&gt;“Single Value Decomposition (SVD)”&lt;/strong&gt; on h and we can get &lt;strong&gt;U&lt;em&gt;S&lt;/em&gt;V’=h&lt;/strong&gt; (V’ is the transpose of V). So by applying SVD on h we get following :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;U =
   -0.4085    0.9116   -0.0445
   -0.8162   -0.3867   -0.4292
   -0.4085   -0.1390    0.9021

S =
    0.3749         0         0
         0    0.0000         0
         0         0    0.0000

V =
   -0.4085   -0.3497   -0.8431
   -0.8162    0.5534    0.1660
   -0.4085   -0.7559    0.5115﻿

&lt;/div&gt;

&lt;p&gt;If you observe decomposed matrices we again see “S” which is rank 1 matrix hence, we can again decompose it into simpler form. We can do &lt;strong&gt;s1&lt;em&gt;s2=S**. Initially we had U&lt;/em&gt;S&lt;em&gt;V’=h . So now we have (U&lt;/em&gt;s1) * (s2*V’)=h. Thus we are reaching close to our goal of representing h in form of **h = h1 * h2&lt;/strong&gt; where, &lt;strong&gt;h1&lt;/strong&gt; and &lt;strong&gt;h2&lt;/strong&gt; are one-dimensional.&lt;/p&gt;

&lt;p&gt;Now to divide &lt;strong&gt;S&lt;/strong&gt; we can again chose SVD but as it is very simple matrix so , we can use square root to divide &lt;strong&gt;S&lt;/strong&gt; as follows&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;h1 = U*sqrt(S)

h1 =
   -0.2501    0.0000   -0.0000
   -0.4997   -0.0000   -0.0000
   -0.2501   -0.0000    0.0000

h2 = sqrt(S)*V&#39;

h2 =
   -0.2501   -0.4997   -0.2501
   -0.0000    0.0000   -0.0000
   -0.0000    0.0000    0.0000
&lt;/div&gt;

&lt;p&gt;So now we have simplified two-dimensional h into h1 and h1 which are one dimensional.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
h1 =
    0.2501
    0.4997
    0.2501
h2 =
    0.2501    0.4997    0.2501&lt;/p&gt;

&lt;p&gt;h1*h2&lt;/p&gt;

&lt;p&gt;ans = h
    0.0626    0.1250    0.0626
    0.1250    0.2497    0.1250
    0.0626    0.1250    0.0626
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hence by using &lt;strong&gt;h1&lt;/strong&gt; and &lt;strong&gt;h2&lt;/strong&gt; we are getting back &lt;strong&gt;h&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Now we can take one-dimensional filter [0.2501 0.4997 0.2501] and apply it on our image to get effect of original Gaussian blur function we had. Lets say our image had X and Y dimension then we apply this one-dimensional filter on X direction first and then we apply same filter on Y direction to get desired result.&lt;/p&gt;
</description>
        <pubDate>Sun, 29 Oct 2017 15:13:36 +0100</pubDate>
        <link>https://pixelclear.github.io/technical/post/2017/10/29/Understanding-Image-Filter-Seperability.html</link>
        <guid isPermaLink="true">https://pixelclear.github.io/technical/post/2017/10/29/Understanding-Image-Filter-Seperability.html</guid>
        
        
        <category>technical</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Over Draw Count is your enemy!!</title>
        <description>&lt;h1 id=&quot;what-is-overdraw-count-&quot;&gt;&lt;strong&gt;What is overdraw count ?&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Mostly on embedded hardware the major concern for performance drop could be overdraw. Basically one pixel on screen is shaded multiple times by the GPU due to nature of geometry or scene we are drawing and this is called as overdraw. There are many tools to visualize overdraw count.&lt;/p&gt;

&lt;h1 id=&quot;details-about-overdraw&quot;&gt;&lt;strong&gt;Details about overdraw?&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;When we draw some vertices those vertices will be transformed to clip space then to window coordinates. Rasterizer then maps this coordinates to pixels/fragments.Then for pixels/fragments GPU calls pixel shader. There could be cases when we are drawing multiple instance of geometry and blending them. So, this will do drawing on same pixel multiple times.This will lead to overdraw and could degrade performance.&lt;/p&gt;

&lt;h1 id=&quot;strategies-to-avoid-overdraw&quot;&gt;&lt;strong&gt;Strategies to avoid overdraw?&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;1.&lt;em&gt;Consider Frustum culling&lt;/em&gt; - Do frustum culling on CPU so that objects out of cameras field of view will not be rendered.&lt;/p&gt;

&lt;p&gt;2.&lt;em&gt;Sort objects based on z&lt;/em&gt; - Draw objects from front to back this way for later objects z test will fail and the fragment wont be written.&lt;/p&gt;

&lt;p&gt;3.&lt;em&gt;Enable back face culling&lt;/em&gt; - Using this we can avoid rendering back faces that are looking towards camera.&lt;/p&gt;

&lt;p&gt;If you observe point 2, we are rendering in exactly reverse order for blending.We are rendering from back to front. We need to do this because blending happens after z test. If for any fragment fails z test then though it is at back we should still consider it as blending is on but, that fragment will be completely ignored giving artifacts.Hence we need to maintain order from back to front. Due to this when blending is enabled we get more overdraw count.&lt;/p&gt;

&lt;h1 id=&quot;why-we-need-per-pixel-mutex&quot;&gt;&lt;strong&gt;Why we need Per Pixel Mutex?&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;By nature GPU is parallel so, shading of pixels can be done in parallel. So there are many instance of pixel shader running at a time. This instances may be shading same pixel and hence accessing same pixels.This may lead to some synchronization issues.This may create some unwanted effects. In this application I am maintaining overdraw count in image buffer initialized to 0. The operations I do are in following order.&lt;/p&gt;

&lt;p&gt;a) Read i pixels count from image buffer (which will be zero for first time)&lt;/p&gt;

&lt;p&gt;b) Add 1 to value of counter read in step 1&lt;/p&gt;

&lt;p&gt;c) Store new value of counter in ith position pixel in image buffer&lt;/p&gt;

&lt;p&gt;As I told you multiple instance of pixel shader could be working on same pixel this may lead to corruption of counter variable.As these steps of algorithm are not atomic. I could have used inbuilt function &lt;strong&gt;imageAtomicAdd()&lt;/strong&gt;. I wanted to show how we can implement per pixel mutex so, I have not used inbuilt function &lt;strong&gt;imageAtomicAdd()&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;#version 430


layout(binding = 0,r32ui) uniform uimage2D overdraw_count;
layout(binding = 1,r32ui) uniform uimage2D image_lock;

void mutex_lock(ivec2 pos)
{
  uint lock_available;
 do
 {
   lock_available = imageAtomicCompSwap(image_lock, pos, 0, 1);

 }while( lock_available == 0);
}

void mutex_unlock(ivec2 pos)
{
  imageStore(image_lock, pos, uvec4(0));
}

out vec4 color;
void main()                                                                                 
{                  
     mutex_lock(ivec2(gl_FragCoord.xy));           
     uint count = imageLoad(overdraw_count, ivec2(gl_FragCoord.xy)).x;
	 count = count+1;
	 imageStore(overdraw_count, ivec2(gl_FragCoord.xy), uvec4(count));
	 mutex_unlock(ivec2(gl_FragCoord.xy));                                                
}

Fragment_Shader.fs

&lt;/div&gt;

&lt;h1 id=&quot;about-demo&quot;&gt;&lt;strong&gt;About Demo&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;In demo video you can see we are rendering many teapots and blending is on.So pixels with more intensity shows there overdraw count is high.&lt;/p&gt;

&lt;p&gt;Note : On android you can see this overdraw count in debug GPU options.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/Ko8ctJQeewY&quot;&gt;Demo Of OverDraw Count&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 29 Oct 2017 15:13:36 +0100</pubDate>
        <link>https://pixelclear.github.io/technical/post/2017/10/29/Over-Draw-Count.html</link>
        <guid isPermaLink="true">https://pixelclear.github.io/technical/post/2017/10/29/Over-Draw-Count.html</guid>
        
        
        <category>technical</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Dynamic LODs using adaptive Tessellation!!</title>
        <description>&lt;p&gt;&lt;img src=&quot;../assets/Tess0.png&quot; alt=&quot;Tessellation overview&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;what-was-done-before-programmable-pipeline-&quot;&gt;&lt;strong&gt;What was done before programmable pipeline ?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Dynamic level of details previous to programmable pipeline used to be implemented on CPU and then push modified vertices down the pipeline. There were two distinct disadvantages to this scheme,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;we are bound by bus bandwidth when copying new generated vertices from CPU to GPU.As the level of detail increases and hence, more number of vertices needs to be copied.This will degrade performance of your application and make it bus bandwidth bound.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Whole work load of sub dividing surfaces is on CPU side hence, not taking much advantage of parallel nature of GPU. If there are very high level of details, work of CPU will be more. This will result in degrading performance and making your application CPU bound.&lt;/p&gt;

    &lt;p&gt;Other solution to subdivision of surfaces on CPU is to keep multiple copies of Mesh with different LOD active in memory and depending on distance from eye position draw appropriate Mesh. Again this solution is not scalable and there is limited VRAM available and hence not best solution.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;whats-with-programmable-pipeline&quot;&gt;&lt;strong&gt;Whats with Programmable Pipeline?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;We now with programmable pipeline have tessellation shader stage.For given patch (patch is just bunch of vertices forming new primitive for tessellation) we can decide the outer and inner tessellation level on the fly and this will generate and produce new vertices on the fly. Following are advantages&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;We can start with very low poly model. Hence when we sending vertices from CPU to GPU load is minimum.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We are generating vertices on fly so whole workload is on GPU.  As vertex shader runs per vertex ,Tessellation Control Shader is called per patch and this invocations could be in parallel . Also next stage of tessellation which is Fixed Function stage (Primitive Generator) will also be heavily parallel. Hence we are taking full advantages of GPU.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;how-we-can-implement-it&quot;&gt;&lt;strong&gt;How we can implement it?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;There are couple of methods on how we can implement it.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;View Distance Dependent Method&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sphere diameter in clip Space Method&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this article I have implemented first method. It is pretty straight forward to implement it.Following is the algorithm that describes those steps&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;For every edge of the primitive find distance of that edge and Eye Position.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Depending on this distance decide the Outer and inner tessellation levels.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;problems-with-method-i-have-implemented-&quot;&gt;&lt;strong&gt;Problems with method I have implemented ?&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;For the primitives that share edges the outer tessellation level needs to be carefully generated.The outer tessellation level generated for edges shared by primitives must match else we will get cracks.For different orientations sometimes its very tricky to match this levels. Outer tessellation level decides how edge of the primitive will be divided while , inner tessellation level deals with how inner part of patch will be divided. Please see images below ( Credit to NVDIA )&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Tess1.png&quot; alt=&quot;Tessellation Artifacts&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Tess2.jpg&quot; alt=&quot;Tessellation Artifacts&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;about-demo&quot;&gt;&lt;strong&gt;About Demo&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;In start of the demo you will see I have loaded low poly version of model. After that, I enable dynamic LODs and you see more number of vertices generated as I move mode close and far from Eye Positions.
&lt;a href=&quot;https://youtu.be/ay3cHWwKi90&quot;&gt;Tessellation Video&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 29 Oct 2017 15:13:36 +0100</pubDate>
        <link>https://pixelclear.github.io/technical/post/2017/10/29/Dynamic-Tessellation.html</link>
        <guid isPermaLink="true">https://pixelclear.github.io/technical/post/2017/10/29/Dynamic-Tessellation.html</guid>
        
        
        <category>technical</category>
        
        <category>post</category>
        
      </item>
    
  </channel>
</rss>
